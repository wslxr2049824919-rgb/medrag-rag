# 医学问答 RAG 系统数据分析与设计说明  
（基于 PubMed RCT 数据集的句子级 RAG MVP）

## 1. 项目概述

本项目目标是搭建一个面向医学领域的问答型 RAG（Retrieval-Augmented Generation）系统原型（MVP），能够：

- 基于真实医学文献（PubMed 随机对照试验，Randomized Controlled Trial, RCT）检索相关句子；
- 将检索到的专业文本作为上下文，辅助本地大模型生成更加可靠的中文医学回答；
- 在当前阶段聚焦于**数据加载与评估**、**文本特征分析**与**分割策略设计**，为后续扩展与上线版本打基础。

技术栈与部署方式（当前版本）：

- **数据源**：HuggingFace 数据集 `armanc/pubmed-rct20k`
- **本地大模型（LLM）**：`qwen3:8b`（通过 Ollama 调用）
- **嵌入模型（Embedding）**：`nomic-embed-text`（通过 Ollama 调用）
- **向量数据库**：Chroma（本地持久化目录 `./chroma_medrag_mvp`）
- **框架**：LangChain（`langchain_community` 组件）
- **数据加载与分析脚本**：
  - `src/data_overview.py`：字段与缺失情况分析
  - `src/data_length_stats.py`：文本长度分布分析
  - `src/label_stats.py`：label 取值分布分析
  - `src/word_freq.py`：简单词频统计

本说明文档聚焦于以下几部分：

1. 数据集事实：大小、字段情况、缺失情况与基础质量；
2. 文本长度分布与特征量化分析；
3. 领域语言特性：label 结构、高频术语与文本风格；
4. 文本分割策略设计及原因；
5. RAG 系统架构与关键设计决策；
6. 当前局限与后续工作计划。

---

## 2. 数据集事实（结构、字段与缺失情况）

### 2.1 数据集来源与划分

本项目采用的数据集为：

- **名称**：PubMed RCT  
- **HuggingFace ID**：`armanc/pubmed-rct20k`  
- **加载方式**：通过 `datasets.load_dataset("armanc/pubmed-rct20k")` 在线加载。

`src/data_overview.py` 的运行结果显示，数据集划分及规模为：

- `train`：**176,642** 行  
- `validation`：**29,672** 行  
- `test`：**29,578** 行  

每一行代表**摘要中的一句话**，因此这是一个“**句子级**”的医学文本数据集，适合作为构建句子级知识库的基础。

### 2.2 字段说明

三个 split（train/validation/test）的字段结构一致，均包含以下四个字段（来自终端输出）：

- `abstract_id`：  
  摘要编号，用于标识一篇完整的论文摘要。  
  同一个 `abstract_id` 下可以有多条句子（多行 `text`）。

- `sentence_id`：  
  句子在该摘要内部的编号（序号），从 0 开始递增。  
  可以用 `(abstract_id, sentence_id)` 唯一定位到一条句子。

- `label`：  
  表示该句子在摘要整体结构中的角色标签，后文将详细分析。

- `text`：  
  句子内容（英文医学文本），为 RAG 系统的**主要检索与嵌入对象**。

> 说明：  
> 数据集中**不包含** `title`、`journal`、`pub_date` 等字段，  
> 因此当前阶段不考虑按期刊 / 发表年份作为检索过滤条件（例如“近 5 年 Nature 文献”），也暂不引入 PMID 作为追溯原文链接。

### 2.3 字段完整性与 NaN 缺失情况

在 `data_overview.py` 中，将 `train` 集转换为 `pandas.DataFrame` 后，对四个字段进行了 NaN 缺失率统计：

- DataFrame 形状（train）：`(176642, 4)`
- 各字段 NaN 缺失比例（终端输出）：

  - `abstract_id`：**0.0**
  - `label`：**0.0**
  - `text`：**0.0**
  - `sentence_id`：**0.0**

**结论：**

- 在结构层面，四个字段均无 NaN 缺失，字段完整性非常好；
- 不需要为 NaN 做填充或丢弃策略，可以直接进入后续质量分析。

### 2.4 文本基础质量分析（极短文本与“怪样本”）

为了识别潜在的“异常样本”（例如空字符串、只有符号的句子等），`data_overview.py` 对 `text` 字段做了进一步质量检查：

- 将 `text` 转为字符串并 strip 首尾空白；
- 统计：
  - 空字符串 / 仅空白字符占比；
  - 字符长度 < 10 的“极短文本”占比。

统计结果（终端输出）：

- **空字符串或仅空白**：约 **0.0000%** —— 几乎不存在；
- **极短文本（长度 < 10 字符）**：约 **0.0617%**。

抽样查看的极短文本示例如：

- `'no .'`
- `'P < @O .'`
- `'@ ) .'`
- `'Purpose /'`
- `'N/A .'`
- `'NCT@ ) .'`
- `'@ dogs .'` 等。

可以看出：

- 这些样本大多为非常简短的回答、缩写或符号化字符串，信息量有限；
- 从比例来看，极短文本在整体数据中的占比**远低于 1%**，对整体分布影响非常有限。

**清洗策略建议（当前阶段）：**

- 鉴于极短文本占比极低，本阶段可选择**暂时保留**，不额外过滤；
- 如果后续在检索评估中发现极短文本影响效果，可在构建向量库时增加简单过滤规则（例如：`len(text) < 10` 的样本不入库）。

---

## 3. 文本长度分布与特征量化分析

本节通过 `data_length_stats.py` 对 `text` 字段进行长度分布分析，从**字符数**和**单词数**两个维度量化文本特征，并与嵌入模型的 token 上限进行对比。

### 3.1 字符长度分布（char_len）

对 train 集 176,642 条样本，计算字符长度 `char_len = len(text)`，得到主要分布统计如下（终端输出）：

- 样本数：`count = 176642`
- 平均值（mean）：≈ **151.3** 字符  
- 标准差（std）：≈ **76.5** 字符  
- 最小值（min）：**1** 字符  
- 中位数（50%）：**138** 字符  
- 90% 分位数：**248** 字符  
- 95% 分位数：**291** 字符  
- 99% 分位数：**396** 字符  
- 最大值（max）：**1386** 字符  

**解读：**

- 大多数句子的字符长度集中在 100–300 字符之间；
- 99% 的句子字符长度不超过约 400 字符；
- 绝对最长的句子为 1386 字符，为少数“长段落式”句子。

### 3.2 单词数分布（word_len）

同时基于空格拆分粗略计算单词数 `word_len = len(text.split())`，得到分布情况：

- 样本数：`count = 176642`
- 平均值（mean）：≈ **26.7** 个单词  
- 标准差（std）：≈ **15.3** 个单词  
- 最小值（min）：**1** 个单词  
- 中位数（50%）：**24** 个单词  
- 90% 分位数：**45** 个单词  
- 95% 分位数：**55** 个单词  
- 99% 分位数：**80** 个单词  
- 最大值（max）：**296** 个单词  

**解读：**

- 绝大部分句子长度在 20–50 个单词之间；
- 单句文本信息密度较高，经常在一句话中描述完整的临床比较或统计结果；
- 极少数长句子接近或超过 200 个单词，但比例非常低。

### 3.3 与嵌入模型 token 上限的关系

当前选用的嵌入模型（例如 `nomic-embed-text`）通常具有约 **512 token** 的输入上限。为了粗略评估“是否有句子会超过 token 上限”，`data_length_stats.py` 中采用如下保守估算：

- 假设 **512 token ≈ 2000 字符**（对英文文本而言是偏保守的上界）；
- 在脚本中设定字符阈值 `approx_char_limit_for_512_tokens = 2000`；
- 统计 `char_len > 2000` 的样本数量及比例。

结果（终端输出）：

- **超过 2000 字符的样本数：0 条**  
- **占比：0.0000%**

结合之前的最大值 `max char_len = 1386`，可以认为：

- 当前数据集中**不存在**任何一条句子长度接近或超过 2000 字符；
- 即使考虑 512 token 上限，**单句级文本完全在可接受范围内**。

**结论：**

> 在当前“句子级”建库方式下，所有 `text` 的长度均远低于嵌入模型 512 token 上限，不需要为了 token 限制对句子进行切分。

---

## 4. 领域语言特性分析（医学文本风格）

本节通过实际数据分析与抽样阅读，对 PubMed RCT 数据集中的医学文本风格做定性总结，支撑“领域内容理解”相关的任务要求。

### 4.1 文本粒度与信息密度

- 当前使用的 `text` 字段为“**摘要中的单句**”，每条样本对应一条完整的临床陈述或结果描述；
- 在长度分布上，中位数约 24 个单词，说明绝大部分文本是偏长句，信息密度较高；
- 在对最长几条样本的抽样阅读中（`data_length_stats.py` 输出的 Top-5 长句），可以看到典型句子往往在一句话中同时包含：
  - 研究人群（如“patients aged over @ years with refractory isolated systolic hypertension”）；
  - 干预措施与对照（如“extended-release isosorbide mononitrate added to standard therapy”）；
  - 多个生理指标（body temperature、respiratory rate、heart rate、white blood cell count 等）；
  - 评分量表（APACHEII score、Glasgow coma score (GCS) 等）；
  - 统计描述（difference of medians、p 值、median [range] 等）。

这些现象表明：**单句文本已经是一个信息高度压缩的“微型结果/方法单元”**，句子级 Document 对 RAG 来说是合理的粒度。

### 4.2 IMRaD 结构的 label 证据

通过 `label_stats.py` 对 train 集的 `label` 字段进行统计，得到：

- `label` 的去重取值列表（终端输出）：

  ```text
  ['background', 'conclusions', 'methods', 'objective', 'results']